# -*- coding: utf-8 -*-
"""Cnn_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15xXVUVvVUPzJ0kZc24ic1XFLyZY83zAa
"""

import kagglehub
path = kagglehub.dataset_download("fahadullaha/facial-emotion-recognition-dataset")
print("Path to dataset files:", path)

data_path = "/root/.cache/kagglehub/datasets/fahadullaha/facial-emotion-recognition-dataset/versions/1/processed_data"

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
from collections import Counter
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

num_epochs = 15
batch_size = 64
learning_rate = 0.001
num_classes = 7

data_dir = "/root/.cache/kagglehub/datasets/fahadullaha/facial-emotion-recognition-dataset/versions/1/processed_data"

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((48,48)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize((0.5,),(0.5,))
])

data_dir = "/kaggle/input/facial-emotion-recognition-dataset/processed_data"

dataset = datasets.ImageFolder(root=data_dir, transform=transform)
print("Classes:", dataset.classes)
print("Total images:", len(dataset))

from collections import Counter

labels = [label for _,label in dataset]
class_counts = Counter(labels)

counts = torch.tensor([class_counts[i] for i in range(len(dataset.classes))], dtype=torch.float)
weights = (1/counts)
weights = weights / weights.sum() * len(counts)
weights = weights.to(device)

train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size

train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)

print(f"Train Samples = {len(train_dataset)}")
print(f"Test Samples  = {len(test_dataset)}")
print("Class Labels =", dataset.classes)

class CNNModel(nn.Module):
    def __init__(self, num_classes=7):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1,32,3,padding=1), nn.ReLU(),
            nn.Conv2d(32,32,3,padding=1), nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32,64,3,padding=1), nn.ReLU(),
            nn.Conv2d(64,64,3,padding=1), nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(64,128,3,padding=1), nn.ReLU(),
            nn.Conv2d(128,128,3,padding=1), nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.classifier = nn.Sequential(
            nn.Linear(128*6*6,256), nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256,num_classes)
        )

    def forward(self,x):
        x=self.features(x)
        x=x.view(x.size(0),-1)
        return self.classifier(x)


model = CNNModel(num_classes=len(dataset.classes)).to(device)
criterion = nn.CrossEntropyLoss(weight=weights)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

best_accuracy = 0
train_losses, train_accs, test_accs = [], [], []
print("Model Ready ✔")

for epoch in range(15):
    model.train()
    running_loss, correct, total = 0,0,0

    for images,labels in train_loader:
        images,labels = images.to(device),labels.to(device)

        output = model(images)
        loss = criterion(output,labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()*images.size(0)
        _,predicted = output.max(1)
        correct += predicted.eq(labels).sum().item()
        total   += labels.size(0)

    train_loss = running_loss / len(train_loader.dataset)
    train_acc  = 100*correct/total

    # ---------- Evaluate on Test ----------
    model.eval()
    test_correct,test_total=0,0
    with torch.no_grad():
        for images,labels in test_loader:
            images,labels=images.to(device),labels.to(device)
            out=model(images)
            _,pred=out.max(1)
            test_correct+=pred.eq(labels).sum().item()
            test_total+=labels.size(0)

    test_acc = 100*test_correct/test_total

    train_losses.append(train_loss)
    train_accs.append(train_acc)
    test_accs.append(test_acc)

    print(f"Epoch {epoch+1}/15 | Loss={train_loss:.4f} | Train={train_acc:.2f}% | Test={test_acc:.2f}%")

    if test_acc > best_accuracy:
        best_accuracy = test_acc
        torch.save(model.state_dict(),"best_model.pth")
        print("Best Model Saved!")

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(train_losses,'b',label='Loss')
plt.title("Loss Curve"); plt.legend()

plt.subplot(1,2,2)
plt.plot(train_accs,'g',label="Train Acc")
plt.plot(test_accs,'r',label="Test Acc")
plt.title("Accuracy Curve"); plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

model.load_state_dict(torch.load("best_model.pth"))
model.eval()

all_true, all_pred = [], []

with torch.no_grad():
    for img,lbl in test_loader:
        img,lbl = img.to(device),lbl.to(device)
        out=model(img)
        _,p=out.max(1)
        all_true += lbl.cpu().tolist()
        all_pred += p.cpu().tolist()

cm = confusion_matrix(all_true, all_pred)
disp = ConfusionMatrixDisplay(cm, display_labels=dataset.classes)
disp.plot(cmap="Blues",xticks_rotation=45)
plt.title("Confusion Matrix")
plt.show()

def show(img,title):
    img=img*0.5+0.5
    img=np.transpose(img.numpy(),(1,2,0))
    plt.imshow(img,cmap='gray')
    plt.title(title)
    plt.axis('off')
    plt.show()

images,labels = next(iter(test_loader))
images,labels = images.to(device),labels.to(device)
out=model(images); _,pred=out.max(1)

for i in range(5):
    show(images[i].cpu(), f"PRED → {dataset.classes[pred[i]]} | REAL → {dataset.classes[labels[i]]}")